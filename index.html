<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Tone Adjustment, Image Enhancement, CLIP">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CLIPtone: Unsupervised Learning for Text-based Image Tone Adjustment</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CLIPtone: Unsupervised Learning for Text-based Image Tone Adjustment</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/hmin970922/">Hyeongmin Lee</a><sup>*</sup>,
            </span>
            <span class="author-block">
              <a href="https://kkang831.github.io/">Kyoungkook Kang</a><sup>*</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.scho.pe.kr/">Jungseul Ok</a>,
            </span>
            <span class="author-block">
              <a href="https://www.scho.pe.kr/">Sunghyun Cho</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">POSTECH</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">CVPR 2024</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <!-- Supple Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supple</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/hmin970922/CLIPtone"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section>
 -->
  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
      <img src="./static/images/Teaser.png"
           class="interpolation-image"
           alt="Teaser."/>
      <!-- <h2 class="subtitle has-text-centered"> -->
      <h2 class="subtitle is-full-width">
        We present CLIPtone, a text-based image tone adjustment framework trained in an unsupervised manner.
        With its superior understanding of natural languages, CLIPtone is capable of performing successful adjustments across a range of text descriptions, including those previously deemed impossible.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent image tone adjustment (or enhancement) approaches have predominantly adopted supervised learning for learning human-centric perceptual assessment. However, these approaches are constrained by intrinsic challenges of supervised learning.
            Primarily, the requirement for expertly-curated or retouched images escalates the data acquisition expenses.Moreover, their coverage of target style is confined to stylistic variants inferred from the training data. 
          </p>
          <p>
            To surmount the above challenges, we propose an unsupervised learning-based approach for text-based image tone adjustment method, CLIPtone, that extends an existing image enhancement method to accommodate natural language descriptions. 
            Specifically, we design a hyper-network to adaptively modulate the pretrained parameters of the backbone model based on text description.
            To assess whether the adjusted image aligns with the text description without ground truth image, we utilize CLIP, which is trained on a vast set of language-image pairs and thus encompasses knowledge of human perception.
            The major advantages of our approach are three fold: (i) minimal data collection expenses, (ii) support for a range of adjustments, and (iii) the ability to handle novel text descriptions unseen in training.
            Our approach's efficacy is demonstrated through comprehensive experiments, including a user study.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
    <!--/ Abstract. -->
<section class="section">
  <div class="container is-max-desktop">
    <!--/ Abstract. -->

    <!-- Method. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified"> -->    
      <div class="columns is-centered">      
        <div class="column is-full-width">
          <h2 class="title is-3">Method</h2>
          <p>
            We propose modeling the spectro-polarimetric field $f(\cdot)$ using NeSpoF, 
            a neural representation that describes the Stokes vector $\mathbf{s}$ and volumetric density $\sigma$ 
            for the input variables of position, direction, and wavelength.
          </p>

          <div class="column is-centered has-text-centered"><p>$\mathbf{s}, \sigma = F_\Theta(x,y,z,\theta, \phi, \lambda)$</p></div>

          <img src="./static/images/Method.png"
                 class="interpolation-image"
                 alt="Network architecture."
                 width="100%"/>
          
          <p>
            We design NeSpoF with a positional MLP, $F_\Theta^p$, and a spectro-directional MLP, $F_\Theta^d$ and turn to model
            a physically-valid Stokes vector ($s_0^2 \geq s_1^2+s_2^2+s_3^2$) by using intermediate polarimetric properties 
            as outputs ($s_0$, $\rho$, $\chi$, and $\psi$).
            Additionally, we perform coordinate conversions of Stokes vectors since the polarization state of a light ray can be 
            described differently with Stokes vectors at different coordinates.
          </p>
        </div>
      </div>
    <!--/ Method. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
      <div class="columns is-centered">      
        <div class="column is-full-width">
          <h2 class="title is-3">Result</h2>
          <p>
            We built a portable hyperspectral polarimetric imaging system, consisting of a monochromatic camera, LCTF that controls the transmitted wavelength, 
            and a quarter wave plate mounted on a motorized rotation stage.
          </p>
          
          <img src="./static/images/imaging_system.PNG"
                 class="interpolation-image"
                 alt="Network architecture."
                 width="100%"/>

          <!-- <p>
            We capture a scene for 21 wavelengths and 4 quarter-wave plate angles and reconstruct 
            per-pixel Stokes vector by solving a least-squares problem with spatially-varying spectro-polarimetric calibration using these captured images.
          </p> -->
        </div>
      </div>
  </div>
</section>
    

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
