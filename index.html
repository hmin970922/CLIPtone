<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CLIPtone">
  <meta name="keywords" content="Tone Adjustment, Image Enhancement, CLIP">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CLIPtone: Unsupervised Learning for Text-based Image Tone Adjustment</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CLIPtone: Unsupervised Learning for Text-based Image Tone Adjustment</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://hmin970922.github.io/">Hyeongmin Lee</a><sup>1,*</sup>,
            </span>
            <span class="author-block">
              <a href="https://kkang831.github.io/">Kyoungkook Kang</a><sup>2,*</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/view/jungseulok">Jungseul Ok</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.scho.pe.kr/">Sunghyun Cho</a><sup>1,2</sup>
            </span>
          </div>
          <p class="has-text-centered has-text-weight-bold" style="margin-top: -1px; font-size: 0.85rem;">
            (* Equal contribution)
          </p> <!-- Adjusted space with margin-bottom -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">POSTECH <sup>1</sup>GSAI & <sup>2</sup>CSE</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">CVPR 2024</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2404.01123/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/hmin970922/CLIPtone/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

 -->
  
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/Teaser.png"
           alt="Teaser."/>
      <div class="content has-text-justified">
        <p>
        We present CLIPtone, a text-based image tone adjustment framework trained in an unsupervised manner.
        With its superior understanding of natural languages, CLIPtone is capable of performing successful adjustments across a range of text descriptions, including those previously deemed challenging.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent image tone adjustment (or enhancement) approaches have predominantly adopted supervised learning for learning human-centric perceptual assessment. However, these approaches are constrained by intrinsic challenges of supervised learning.
            Primarily, the requirement for expertly-curated or retouched images escalates the data acquisition expenses. Moreover, their coverage of target style is confined to stylistic variants inferred from the training data. 
          </p>
          <p>
            To surmount the above challenges, we propose an unsupervised learning-based approach for text-based image tone adjustment method, CLIPtone, that extends an existing image enhancement method to accommodate natural language descriptions. 
            Specifically, we design a hyper-network to adaptively modulate the pretrained parameters of the backbone model based on text description.
            To assess whether the adjusted image aligns with the text description without ground truth image, we utilize CLIP, which is trained on a vast set of language-image pairs and thus encompasses knowledge of human perception.
            The major advantages of our approach are three fold: (i) minimal data collection expenses, (ii) support for a range of adjustments, and (iii) the ability to handle novel text descriptions unseen in training.
            Our approach's efficacy is demonstrated through comprehensive experiments, including a user study.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
  
    <!--/ Abstract. -->
<section class="section">
  <div class="container is-max-desktop">
    <!--/ Abstract. -->

    <!-- Method. -->
      <div class="columns is-centered has-text-centered">      
        <div class="column is-full-width">
          <h2 class="title is-3">Method</h2>
          <img src="./static/images/Method.png"
                 class="interpolation-image"
                 alt="Network architecture."
                 width="100%"/>
          <div class="content has-text-justified">
          <p>
            CLIPtone consists of a text adapter and a tone adjustment network.
            From a target text description, the text adapter calculates a directional vector within the CLIP embedding space from the source to target text descriptions and estimates the modulation parameter ∆θ for the AdaInt module and the weight predictor of the tone adjustment network.
            The modulated tone adjustment network adaptively constructs an image-text adaptive 3D LUT through fusing basis 3D LUTs and non-uniform sampling, ultimately adjusting the color values of an input image.
          </p>
          </div>
        </div>
      </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">  
      <h2 class="title is-3" style="text-align: center;">Results</h2>
      <div id="results-carousel" class="carousel results-carousel" data-slides-to-show="1">
        <div class="item item-results1">
          <img src="./static/images/Results_1.png" id="Results_1" height="100%">
        </div>
        <div class="item item-results2">
          <img src="./static/images/Results_2.png" id="Results_2" height="100%">
        </div>
        <div class="item item-results3">
          <img src="./static/images/Results_3.png" id="Results_3" height="100%">
        </div>
        <div class="item item-results4">
          <img src="./static/images/Results_4.png" id="Results_4" height="100%">
        </div>
      </div>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/abs/2404.01123/" class="external-link" disabled>
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/hmin970922/CLIPtone/" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            The website template is borrowed from 
            <a href="https://github.com/nerfies/nerfies.github.io"><span class="dnerf">Nerfies</span></a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
